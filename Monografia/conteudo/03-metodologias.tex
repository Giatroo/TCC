%!TeX root=../tese.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Materiais e Métodos}%
\label{cha:materiais_e_metodos}

Este capítulo abordará os principais recursos utilizados na experimentação com o
modelo DeBERTa na tarefa de detecção automática de sarcasmo. Inicialmente,
falar-se-á um pouco sobre o modelo em si e como ele aborda alguns dos problemas
anteriormente encontrados na literatura. Depois, abordar-se-á o conjunto de
dados utilizado nos experimentos. Por fim, discutir-se-á o código em si e as
ferramentas pré-existentes que foram utilizadas neste trabalho.

\section{DeBERTa}%
\label{sec:deberta}

O modelo DeBERTa foi criado por um grupo de pesquisadores da Microsoft e
publicado em 2021 (~\cite{he-etal:2020:deberta}). Seu nome é uma sigla que
significa ``\textit{Decoding-Enhanced BERT with Disentangled Attention}'' (em
tradução livre, ``BERT com decodificação melhorada por atenção decomposta'').
Como o nome já sugere, o DeBERTa foi criado com o modelo
BERT~(\cite{devlin-etal:2018:bert}) como uma base, mas também tem principal
inspiração o modelo RoBERTa~(\cite{liu-etal:2019:roberta}), que é outro modelo
que propõe melhorias para o BERT.

Suas principais contribuições para a área são duas: \textit{disentangled
attention} (em tradução livre, ``atenção decomposta'') e \textit{enhanced mask
decoder} (em tradução livre, ``decodificador de máscara
melhorado'')~\footnote{Assim como alguns outros termos utilizados nessa
monografia, optou-se por não traduzir \textit{disentangled attention}
e \textit{enhanced mask decoder} pelo fato de serem termos muito novos na
literatura e não terem uma tradução canônica para o português.}.

A primeira e mais importante contribuição é a \textit{disentangled attention}.
Como visto em \ref{sub:transformers}, os modelos \textit{transformers} possuem
o problema de não conseguirem mapear muito bem a distância entre os elementos da
sequência de entrada. Assim como no artigo original de
\cite{vaswani-etal:2017:attention-is-all-you-need}, o modelo BERT também utiliza
uma soma da codificação dos elementos da sequência com uma codificação de
posições da sequência. Ao somar entretanto, perde-se um pouco do conteúdo
original de cada uma das codificações. No mecanismo de \textit{disentangled
attention}, o \textit{conteúdo} (ou seja, a codificação dos elementos da
sequências - em geral, palavras) e a \textit{posição} são representados
utilizando dois vetores diferentes. E as atenções entre as palavras são
computadas utilizando também matrizes distintas e baseadas no conteúdo das
palavras e na sua distância relativa.

Utilizando a própria notação presente no artigo original do modelo
(\cite{he-etal:2020:deberta}), um elemento na posição $i$ de uma sequência é
representado por dois vetores $\bracket{H_i}$ e $\bracket{P_{i\cond j}}$, que
representam respectivamente o conteúdo do elemento e a sua posição relativa com
um outro elemento na posição $j$. Então, a atenção cruzada que os elementos $i$
e $j$ prestam entre si (essa relação é simétrica) é calculada pelo produto
\begin{equation} \label{eq:deberta-atenttion}
\begin{split}
   A_{i,j}&=\bracket{H_i,~P_{i\cond j}}\times\bracket{H_j,~P_{j,i}}^{T} \\
          &=H_iH_j^{T} +
          H_iP_{j\cond i}^{T} +
          P_{i\cond j}H_j^{T} +
          P_{i\cond j}P_{j\cond i}^{T}.
\end{split}
\end{equation}

Portanto, no caso em que as informações relativas ao conteúdo e posição dos
elementos, a atenção total entre $i$ e $j$ pode ser calculada como quatro outras
atenções: conteúdo-para-conteúdo, conteúdo-para-posição, posição-para-conteúdo e
posição-para-posição. Em seu artigo, os autores argumentam que apenas as três
primeiras atenções são realmente úteis e, portanto, descartam o caso de atenção
entre posições relativas.

Vale a notar que os autores fazem uma leve mudança de nomenclatura em seu
artigo. Enquanto originalmente,
\cite{vaswani-etal:2017:attention-is-all-you-need} chamam de atenção o resultado
da equação \ref{eq:self-attention}. \cite{he-etal:2020:deberta} chamam de
atenção apenas o resultado da multiplicação das consultas, $Q$, pelas chaves
$K$. Para fazer uma comparação, no modelo de \textit{self-attention} original,
tem-se:
\[
Q=HW_q,~K=HW_k,~V=HW_v,~A=\dfrac{QK^{T}}{\sqrt{d}}
\]
\[
H_o=\texttt{softmax}(A)V,
\]

onde $H$ representa os vetores de conteúdo, $H_o$ a saída da
\textit{self-attention}, $W_q,W_k,W_v$ são matrizes de pesos aprendidas pela
rede neural e $A$ é a matriz de atenção.

No modelo de \textit{disentangled attention}, entretanto, a atenção é calculada
como
\begin{equation}
\begin{split}
   Q_c=HW_{q,c},~K_c&=HW_{k,c},~V_c=HW_{v,c},~Q_r=PW_{q,r},~K_r=PW_{k,r} \\
   \tilde{A}_{i,j}&=\underbrace{Q^{c}_iK^{cT}_j}_{\text{conteúdo-para-conteúdo}} +
   \underbrace{Q^{c}_iK^{rT}_{\delta(i,j)}}_{\text{conteúdo-para-posição}} +
   \underbrace{K^{r}_jQ^{cT}_{\delta(j,i)}}_{\text{posição-para-conteúdo}} \\
   H_o&=\texttt{softmax}\paren{\dfrac{\tilde{A}}{\sqrt{3d}}}V_c,
\end{split}
\end{equation}

onde $\tilde{A}$ é a matriz de atenção e $\tilde{A}_{i,j}$ representa a atenção
do elemento $i$ para o elemento $j$, $Q^{c}_i$ é a $i$-ésima linha de $Q_c$,
$K^{c}_j$ é a $j$-ésima linha de $K_c$ e $\delta(i,j)$ é uma função que dá a
distância relativa entre $i$ e $j$ (para mais detalhes, ler o artigo original).

Com essa nova forma de calcular a atenção, os autores conseguem dividir as rotas
utilizadas pela informação de forma que o modelo consiga ter aceso a informação
das posições relativas e conteúdos do texto de forma ``limpa'', sem ser por meio
de uma soma como feito em trabalhos anteriores.

Por fim, a segunda contribuição desse modelo é a \textit{enhanced mask decoder},
que é quase uma consequência direta da primeira contribuição mencionada
anteriormente. Ao desacoplar conteúdo e posição, os autores utilizam as posições
relativas entre as palavras, mas esse modelo acaba perdendo as informações das
posições absolutas do texto. Por exemplo, na frase ``A roda do meu carro quebrou
novamente'', o modelo saberia apenas que ``roda'' e ``carro'' possuem uma
distância de 3 posições entre si, mas não saberia que ``roda'' está na segunda
posição do texto. Para endereçar esse problema, o modelo precisa, em algum ponto
de sua arquitetura, receber a informação da posição absoluta das palavras no
texto de entrada.

O modelo BERT recebia essa informação logo no começo, através de uma soma dos
vetores, como já mencionado. Mas o modelo DeBERTa adiciona essa informação
apenas no último passo da arquitetura, logo antes de uma camada
\texttt{softmax} predizer qual é o elemento mascarado que se deseja predizer.
Portanto, o DeBERTa utiliza apenas as posições relativas entre as palavras
durante toda sua arquitetura e recebe a informação das posições absolutas apenas
como um complemento para decodificar as palavras mascaradas. Os autores fazem um
estudo empírico e mostram que essa abordagem é mais eficiente do que a abordagem
utilizada pelo BERT e outros modelos anteriores a esse estudo.

\subsection{DeBERTa V3}%
\label{sub:deberta_v3}

Este trabalho utiliza a nova versão do DeBERTa, o
DeBERTaV3~\cite{he-etal:2021:debertav3}, que é uma melhoria da versão original
utilizando ideias apresentadas por \cite{clark-etal:2020:electra} no modelo
ELECTRA.

O ELECTRA é um modelo que utiliza uma proposta de trocar o \textit{masked
language model} (MLM) utilizado pelo BERT (\ref{sub:bert}) e demais modelos que
o têm o referência (como RoBERTa e DeBERTa) por um novo modelo chamado de
\textit{replaced token detection} (RTD) (do inglês, detecção de símbolo
substituído). Nesse tipo de modelagem, ao invés de substituir alguns
\textit{tokens} aleatoriamente por um símbolo especial \texttt{<MASK>}, troca-se
símbolos válidos por outros símbolos válidos, mas que são gerados por um
gerador. Então, um discriminador é treinado na tarefa de reconhecer quais
símbolos foram trocados pelo gerador e não são os símbolos originais da
sequência. Ao utilizar esse novo tipo de modelagem, os autores demonstram ganhos
significativos na efetividade do modelo.

Além disso, nesse novo modelo, os autores melhoram o modelo ELECTRA ao propor
uma nova forma de treinamento chamada de \textit{gradient-disentangled embedding
sharing} (em tradução livre, \textit{compartilhamento de representação com
gradiente desagradado}). Os autores argumentam que o compartilhamento das
\textit{embeddings} entre o gerador e discriminador é bastante prejudicial para
a tarefa que ambos pretendem realizar, pois o gerador deseja representar
palavras com semânticas similares de forma próxima, enquanto o discriminador
deseja fazer o oposto. Dessa forma, eles propõem uma nova forma de otimização da
rede que desacopla o gradiente utilizado no discriminador do gradiente usado
pelo gerador.

\section{Conjunto de dados SARC}%
\label{sec:conjunto_de_dados_sarc}

Para realizar a detecção de sarcasmo, é necessário um conjunto de dados
rotulados. Muitos trabalhos na literatura utilizam o Twitter (ver
\ref{cha:fundamentos_e_trabalhos_relacionados}), mas há vários trabalhos que,
mais recentemente, têm utilizado o Reddit.

Esta é uma rede social baseada em comunidades. Cada comunidade é chamada de
\textit{subreddit}, e, muitas vezes, referencia-se a elas por tópicos, pois o
nome do \textit{subreddit} define o tipo de publicações que os usuários fazem
dentro dele. Por exemplo, em \texttt{gaming} as pessoas falam sobre jogos, em
\texttt{datascience} as pessoas falam sobre ciência de dados (os nomes
geralmente são bastante autoexplicativos). Além disso, cada postagem feita em um
\textit{subreddit} pode receber comentários e cada comentário, por sua vez, pode
receber sub-comentários (formando uma estrutura recursiva).

\cite{khodak-etal:2017:sarc} em 2017 introduzem um \textit{corpus} de textos
retirados do Reddit que recebeu o nome de SARC, uma sigla para
\textit{Self-Annotated Reddit Corpus} (em tradução livre, ``corpus do Reddit
auto-anotado''). Esse conjunto de dados foi o primeiro a passar de um milhão de
comentários sarcásticos (e mais de quinhentos milhões de comentários no total).
Esse marco deve-se ao fato de este conjunto de dados ser o primeiro a utilizar a
estrutura de comentários do Reddit e rotular o sarcasmo automaticamente, com
base em anotações dos próprios autores dos comentários.

Para rotular um comentário como sarcástico, os autores utilizam o fato de que
muitos usuários do Reddit utilizam a marcação ``\texttt{/s}'' em um comentário
para denotar que estão sendo sarcásticos (de forma similar à \textit{hashtag}
``\textit{\#sarcasm}'' no Twitter)~(\cite{what-does-s-mean}). Dessa forma, todo
comentário encontrado pelos autores com essa marcação é anotado como sendo
sarcástico, enquanto comentários sem essa anotação são marcados como não
sarcásticos.

\begin{figure}[h]
\centering
\includegraphics[scale=0.7]{Res/sarc-img1.jpg}
\caption{Uma postagem e um de seus comentários, que contém a anotação sarcástica
``/s''. Imagem retirada de \cite{khodak-etal:2017:sarc}}
\label{sarc-img1.jpg}
\end{figure}

Os autores, entretanto, reveem seu trabalho e apontam que há uma certa
quantidade de erros cometidos por essa abordagem. Por utilizarem uma metodologia
automática de rotulação, o próprio conjunto de dados acaba possuindo erros do
tipo I e II. Os falsos positivos acontecem quando o algoritmo proposto encontra
um comentário com ``/s'', mas não é sarcástico. Esse tipo de erro pode
acontecer, por exemplo, quando alguém não conhece essa anotação, quando alguém
está referenciando a anotação (como para avisar que um outro usuário esqueceu de
colocá-la ou explicando/perguntando seu significado) ou quando se utiliza a
\textit{tag} de \textit{HTML} \texttt{<s>...</s>}. Os falsos negativos
acontecem, por sua vez, nos comentários que são sarcásticos, mas não utilizam a
marcação. Isso acontece principalmente por dois motivos: o usuário não conhecer
a convenção de utilizar ``/s'' ou por achar que seu sarcasmo é óbvio o
suficiente para que ele não precise utilizar.

Como forma de minimizar esses erros, os autores propõem algumas filtragens.
Algumas delas são bastante padrões como remover URLs e limitar os caracteres aos
da tabela ASCII. Outro filtro é remover os comentários que aparecem após um
comentário sarcástico na árvore de comentários (pois os autores afirmam que
esses comentários são extremamente ruidosos). Além disso, os autores apenas
coletam dados de usuários que estão cientes do uso de ``/s'', verificando se
eles já utilizaram a notação anteriormente. Eles também lidam com os falsos
positivos mantendo apenas os comentários que contém a notação ``/s'' no final do
comentário.

Esses filtros são, então, testados manualmente utilizando uma amostragem de
$1000$ comentários ($500$ sarcásticos e $500$ não sarcásticos). Os autores
demonstram seu procedimento resultou em uma taxa de $1.0\%$ de falsos positivos
e $2.0\%$ de falsos negativos. Por fim, vale dizer que os autores, por motivos
óbvios, removem as anotações ``/s'' dos comentários.

Por fim, os autores disponibilizam várias versões de seu conjunto de dados. Para
este trabalho, utilizou-se a versão balanceada, que é uma tabela na qual cada
linha possui uma postagem e dois comentários referente-se àquela postagem, um
sarcástico e o outro não sarcástico. Além disso, há informações sobre os
usuários autores de cada um dos textos, datas de publicação e em qual
\textit{subreddit} as postagens foram feitas.

Os dados já são separados em treinamento e teste pelos próprios autores,
contendo $109181$ instâncias de treinamento e $27496$ de teste (uma
separação de aproximadamente $20\%$ do total dos dados).
