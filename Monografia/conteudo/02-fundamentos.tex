%!TeX root=../tese.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Fundamentos e Trabalhos Relacionados}%
\label{cha:fundamentos_e_trabalhos_relacionados}

\section{Detecção de Sarcasmo}%
\label{sec:deteccao_de_sarcasmo}

De acordo com o dicionário Dicio, sarcasmo é uma zombaria que busca ofender,
enquanto ironia é a ação de dizer o oposto do que se deseja expressar. Ainda
segundo ele, a diferença entre esses dois termos se dá no fato de que sarcasmo é
um dito ácido que pode ou não ser expresso por meio de uma ironia e essa, por
sua vez, pode ou não ser utilizada para
ofender.~\cite{dicio_sarc, dicio_irony}

\cite{sarcasm:survey}

(R. Giora, On Irony and Negation)

(H. Paul Grice. 1975. Logic and Conversation)

(Irony and Sarcasm: Corpus Generation and Analysis Using Crowdsourcin)

O termo detecção de sarcasmo refere-se à determinação de se há ou não sarcasmo
em uma porção de texto verbal. E o termo detecção automática de sarcasmo
refere-se a métodos computacionais de se resolver o problema acima mencionado.
Computacionalmente, podemos definir esse problema como uma
\textit{\textbf{classificação binária}}, termo explicado mais a frente.

Entretanto, na literatura é bastante comum também se definir detecção de
sarcasmo como a determinação de se há ou não sarcasmo ou ironia verbal em uma
porção de texto verbal. Portanto, em geral, ao se falar de sarcasmo, a
literatura engloba tanto sarcasmo quanto ironia como se fossem a mesma coisa.
Este texto também não fará discriminação entre sarcasmo ou ironia.

Em geral, esse problema é difícil, pois, por vezes, nem humanos conseguem
perceber essa figura de linguagem (e.g. ``\textit{Oba, hoje está tão ensolarado,
que vontade de ir para a escola.}''). Além disso, o contexto tende a importar
muito. Muitas características externas ao texto podem servir para descriminar se
uma pessoa está ou não sendo sarcástica. Entre alguns exemplos estão intonação,
locutor, interlocutor, conhecimento prévio sobre a fala, tempo e espaço em que
se fala e elementos não verbais.~\cite{wallace-etal:2014:ironic-context}

(Humans Require Context to Infer Ironic Intent (so Computers Probably do, too))

\section{Classificação binárias}%
\label{sec:classificacao_binarias}

O problema de detecção de sarcasmo pode ser tratado como uma classificação
binária. Esse tipo de problema é muito estudado no campo do aprendizado de
máquina e envolve classificar os elementos de um conjunto em dois grupos
chamados de classes. Por classificar entende-se a determinação de um elemento do
conjunto entre pertencente à primeira ou segunda classe.

No caso da detecção de sarcasmo, os elementos são os pedaços de texto e as duas
classes são \textit{ser sarcástico} e \textit{não ser sarcástico}. Em termos
matemáticos, tem-se um conjunto de exemplos denotado pela matriz $X$ de
dimensões $n\times m$, onde $n$ é o número de exemplos e $m$ é o número de
características que se usa para descrever cada um desses exemplos. Cada linha de
$X$ é denotada por $\xii[x]{i}$ e chamada de \textit{exemplo} $i$ ou
\textit{instância} $i$.

A linha $\xii[x]{i}$ é um vetor de $m$ posições em que cada posição é uma
característica que descreve a entrada. Por exemplo, na detecção de sarcasmo, o
primeiro valor pode ser a quantidade de palavras lidas, o segundo valor pode ser
a quantidade de caracteres, a terceira pode ser a soma de positividade do texto
(definida por algum critério específico) e assim por diante. É importante que a
mesma posição em diferentes instâncias tenha o mesmo significado. Portanto, caso
se defina que a primeira posição represente o número de palavras, todas as
instâncias devem seguir essa regra.

Cada instância $i$ pertence ou à primeira classe ou à segunda, modela-se isso
por um valor $\xii[y]{i}$ chamado de $i$-ésimo rótulo (do inglês,
\textit{label}). E escreve-se $\xii[y]{i}\in\set{0, 1}$, onde cada valor
representa uma das classes. No caso de sarcasmo, pode-se representar por
\textit{não sarcasmo} o valor $0$ e \textit{sarcasmo}, o valor $1$. Com esses
valores $\xii[y]{i}$ constrói-se um vetor $y$ onde $y_i=\xii[y]{i}$.

Ao final, o problema é descobrir uma função $f$ que mapeie bem $X$ em $y$. Note,
entretanto, que $n$, o número de exemplos, é possivelmente infinito, pois sempre
se pode achar novos exemplos e testar se $f$ os mapeia corretamente. Ou seja,
tenta-se achar essa função $f$ conhecendo parcialmente o conjunto das
instâncias.

\subsection{Métricas de avaliação}%
\label{sub:metricas_de_avaliacao}

Para saber se a função $f$ mapeia bem $X$ em $y$, é preciso definir uma métrica
de avaliação, que é uma função matemática bem definida que indica quanto de erro
se comete em determinado conjunto $X$.

Dado um conjunto de entrada $X$ com $n$ instâncias, seja $y$ o vetor que
representa se cada instância é ou não sarcástica. Seja então $f$ a função sob
avaliação (ou seja, a função de modelagem que recebe os textos e determina se
são ou não sarcásticos). Seja $\hat{y}=f(X)$ os resultados gerados por essa
função.

Note que para cada exemplo $i$, podemos ter duas opções:
\begin{enumerate}
  \item $\hat{y}_i=y_i$  (\textit{acerto})
  \item $\hat{y}_i\neq y_i$ (\textit{erro})
\end{enumerate}

Além disso, pode-se note que o par $\pair{y_i}{\hat{y}_i}$ pode ter quatro
valores:
\begin{enumerate}
  \item $\pair{1}{1}$, caso \textit{verdadeiro positivo} (também conhecido como
    \textit{true positive} e denotado por $tp$).
  \item $\pair{0}{1}$, caso \textit{falso positivo} (também conhecido como
    \textit{false positive} e denotado por $fp$).
  \item $\pair{0}{0}$, caso \textit{verdadeiro negativo} (também conhecido como
    \textit{true negative} e denotado por $tn$).
  \item $\pair{1}{0}$, caso \textit{falso negativo} (também conhecido como
    \textit{false negative} e denotado por $fn$).
\end{enumerate}

Definidos esses valores, pode-se definir algumas métricas que ajudam a perceber
quão boa a função $f$ é. Dessa forma, pode-se comparar duas funções $f$.

\paragraph{Acurácia}%
\label{par:acuracia}

Definida simplesmente como a quantidade total de acertos divido pela quantidade
total de instâncias. Seja $n'$ a quantidade de acertos, então:
\[
\texttt{Acurácia} = \dfrac{n'}{n}
\]

É comum também definir a acurácia em termos dos vamos acima listados:
\[
\texttt{Acurácia} = \dfrac{tp+tn}{tp+tn+fp+fn}
\]

Note que $tp+tn$ representa justamente quando $\hat{y}_i=y_i$ e $fp+fn$,
$\hat{y}_i\neq y_i$.

\paragraph{Precisão}%
\label{par:precisao}

Definida como:
\[
\texttt{Precisão} = \dfrac{tp}{tp+fp}
\]

é a taxa de verdadeiros positivos em relação a todos os positivos. Portanto,
mede a fração de quantos positivos foram acertados em relação a todos os que
existiam no conjunto observado.

\paragraph{Revocação}%
\label{par:revocacao}

Muitas vezes chamada por seu nome em inglês, \textit{recall}, é definida como:
\[
\texttt{Revocação} = \dfrac{tp}{tp+fn}
\]

é a taxa de verdadeiros positivos em relação todas as instâncias preditas como
positivas. Portanto, a fração entre todos as instâncias previstas como positivas
e as instâncias que realmente eram positivas.

A precisão e a revocação guardam uma relação chave entre si e geralmente se quer
ter um bom balanço entre as duas. Observe essa relação a partir do seguinte
exemplo.

Comece com a função
\begin{equation}
  f\paren{\xii[x]{i}} = 1~~\forall i
\end{equation}

Como ela sempre considera a entrada como positiva, então os únicos casos
existentes serão de verdadeiros positivos e falso positivos. Logo:
\[
\texttt{Precisão} = \dfrac{tp}{tp+fp} = \dfrac{tp}{tp+(n-tp)} = \dfrac{tp}{n}
\]
e
\[
\texttt{Revocação} = \dfrac{tp}{tp+fn} = \dfrac{tp}{tp+0} = 1
\]

Portanto, a revocação terá o maior valor possível, enquanto a precisão será
exatamente a fração de valores positivos que o conjunto observado possui. Como,
semanticamente, a revocação é penalizada sempre que um elemento é positivo, mas
foi previsto como negativo, então faz sentido que se tenha uma revocação de
$100\%$, já que não se comete esse tipo de erro.

Agora, tome a função
\begin{equation}
  f\paren{\xii[x]{i}} = 0~~\forall i
\end{equation}

Como ela sempre considera a entrada como negativa, então os únicos casos
existentes serão de verdadeiro negativo e falso negativo. Logo:
\[
\texttt{Precisão} = \dfrac{tp}{tp+fp} = \dfrac{0}{0+fp} = 0
\]
e
\[
\texttt{Revocação} = \dfrac{tp}{tp+fn} = \dfrac{0}{0+fn} = 0
\]

Portanto, como a função nunca tenta marcar uma instância como positiva, ela
nunca acerta os verdadeiros positivos e comete $100\%$ de erro.

\paragraph{Métrica $F_1$}%
\label{par:metrica_f_1_}

Por esses e outros motivos, é interessante agregar a precisão e revocação em um
único valor, que permite fácil comparação entre dois modelos. É possível
utilizar uma média simples desses dois valores, mas é muito mais comum a
utilização da métrica $F_1$ (ou, do inglês, $F_1$ \textit{score}).

Ela é definida como:
\[
F_1=2\cdot
\dfrac{\texttt{precisão}\cdot\texttt{revocação}}
{\texttt{precisão}+\texttt{revocação}}
\]

\section{Trabalhos Relacionados}%
\label{sec:trabalhos_relacionados}

Nessa seção abordar-se-á os trabalhos já realizados na área e as diferentes
abordagens. Pode-se caracterizar os trabalhos por três principais tipos de
abordagens: as baseadas em regras, baseadas em métodos de aprendizado e baseadas
em contexto. Além disso, falar-se-á um pouco sobre as principais características
extraídas dos textos que têm sido utilizadas para melhorar a eficácia das
soluções.

\subsection{Abordagens Baseadas em Regras}%
\label{sub:abordagens_baseados_em_regras}

Abordagens baseadas em regras são aquelas que usam regras fixas para determinar
se uma sequência de palavras contém ou não ironia. Para criar essas regras,
várias características do texto podem ser utilizadas, como as classes sintáticas
das palavras, se são palavras de cunho positivo ou negativo, se há a presença ou
não de certas palavras em uma ordem, entre qualquer outro tipo de regra
imaginável.

Essa abordagem é computacional, porque as regras formam um algoritmo que pode
ser implementado por uma linguagem de computação. Dessa forma, qualquer
sequência de palavras pode ser dada como entrada para o algoritmo e ele
retornará se ele acredita que essa sequência contém ou não sarcasmo.

A principal vantagem desse tipo de abordagem é que ela, além de detectar o
sarcasmo, ajuda a estudá-lo. Ao criar uma regra do tipo \textit{se o texto
possui essas características, então ele é sarcástico} se cria uma explicação
para as principais características presentes em um texto sarcástico.

Entretanto, as metodologias utilizadas são bastante específicas para cada tipo
de texto e cada conjunto de dados. Por exemplo, as regras criadas para um
determinado conjunto da rede social Twitter podem não funcionar em outras redes
sociais como o Facebook, o Instagram ou o WhatsApp, pois cada uma dessas redes
sociais possui um contexto e formato de conversação muito diferente. Portanto,
são modelos que nos permitem explicar o processo de decisão, mas não permitem
fácil generalização.

\cite{veale:2010} investigam em seu artigo sequências da forma ``\textit{as * as
a *''} (``tão * quanto um(a) *''), consideradas como analogias entre o que os
autores chamam de \textit{base} (\textit{ground}) e \textit{meio}
(\textit{vehicle}). Eles utilizam a API do Google para coletar 45021 instâncias
do padrão ``\textit{about as * as *}'' e filtram os resultados na mão para
chegar em 20299 instâncias que de fato são consideradas analogias. Eles então
anotam manualmente os rótulos para essas instâncias e encontraram que 15502
casos ($76\%$) são irônicos e apenas 4797 ($24\%$) são não irônicos.

Então, dado uma sequência ``\textit{as * as a *}'', os autores utilizam
mecanismos de busca na rede como a API do Google para distinguir entre três
casos: os casos em que essa sequência nunca foi usada como ``\textit{about}'';
aqueles que já foram, mas não frequentemente; e aqueles que que são
frequentemente usados com essa marcação. Segundo os próprios autores, essas três
categorias proveem, respectivamente, evidencia fraca contra ironia, evidencia
fraca a favor da ironia e evidência forte para ironia. Ou seja, o caso em que
temos mais certeza de que é uma ironia é o caso em que a sequência é
frequentemente utilizada junto com a palavra ``\textit{about}''.

Assim sendo, \cite{veale:2010} criam um sequência de nove passos para
classificar uma frase desse tipo entre as classes \textit{ironia} e \textit{não
ironia}. Esses passos são bastante claros e precisos, podendo ser, portanto,
implementados por um programa de computador e caracterizando, por conseguinte,
uma detecção automática de sarcasmo.

Nessas regras, os autores utilizam o fato de que analogias mais frequentemente
utilizadas são menos prováveis de serem irônicas, pois a ironia é utiliza
bastante a criatividade do locutor para fazer analogias não usuais.

Devido à natureza das regras propostas pelos autores, eles conseguem medir a
precisão e revocação obtida por cada uma das regras. No geral, o modelo atinge
uma acurácia de $88\%$, o que é um valor bastante alto para esse tipo de
problema. Entretanto, note-se que os autores se limitaram a um escopo muito
fechado (das frases do tipo ``\textit{as * as a *}'').

\cite{maynard-greenwood:2014:cares} exploram o uso de regras baseadas em
hashtags presentes em postagens da rede social Twitter
(\texttt{https://twitter.com/}) e sua aplicação para detecção de sarcasmo em um
contexto mais geral de análise de sentimento.

Em seu artigo, eles utilizam um algoritmo de tokenização de hashtags para
transformá-las em palavras com as quais eles conseguem extrair informação. No
caso, eles utilizam as palavras contidas nas hashtags para avaliar se o
sentimento é positivo ou negativo e inverter o sentido original da frase caso
detectem sarcasmo nas hashtags. Por exemplo, a hashtag \textit{\#notreally} é
tokenizada em \textit{not} e \textit{really} e identificada como uma tag
sarcástica de acordo com regras definidas pelos autores.

Então, eles aplicam cinco regras que podem determinar o sentimento de uma
postagem como \textit{negativo} ou \textit{positivo}, ou então trocar o
sentimento pré-determinado da postagem. Os autores, portanto, fazem uso da
detecção de sarcasmo utilizando hashtags para resolver um outro problema mais
geral que é definir o sentimento predominante de um texto.

Como ponto negativo de sua técnica, está o fato de que nem sempre o tokenizador
de hashtags funciona de forma adequada. Por exemplo, \textit{\#greatstart} pode
ser dividida de duas formas: \textit{greats} e \textit{tart} ou \textit{great}
e \textit{start}. Um ser humano provavelmente saberia que a segunda opção é a
mais provável, mas o algoritmo não sabe fazer essa distinção e acaba ficando com
o primeiro conjunto e palavras. Apesar disso, esse sistema de tokenização possui
um $F1$ de $97,25\%$ e os autores obtiveram $91\%$ de precisão e revocação no
conjunto de dados utilizado por eles.

\cite{bharti-etal:2015:parsing-sarcasm} apresentam duas abordagens baseadas em
regras. A primeira é através da análise morfossintática (do inglês,
\textit{Part-of-Speech Tagging}) e criação de árvores sintáticas (do inglês,
\textit{parse-trees}) que identificam a positividade do sentimento e situação
predominantes em tweets. A segunda é através da análise sintática de tweets que
começam com interjeições.

Em sua primeira abordagem, os autores utilizam dicionários e algoritmos
pré-criados para encontrar as classes morfológicas e sintáticas das palavras.
Então, baseando-se nisso, eles utilizam um algoritmo criado por eles para
encontrar um valor de positividade para o sentimento do texto e para a situação
retratada e, com esses valores, caso seus valores tenham sinais contrários
(sentimento positivo e situação negativa ou vice-versa), eles consideram o texto
como sarcástico. Por exemplo, em ``\textit{I hate Australia in cricket, because
they always win}'' (``eu odeio a Australia no críquete, porque eles sempre
ganham''), as palavras ``\textit{I hate}'' apresentam um sentimento negativo,
enquanto as palavras ``\textit{they always win}'' retratam uma situação
positiva, e, portanto, essa frase seria classificada como sarcástica em sua
primeira abordagem.

Em sua segunda abordagem, os autores utilizam novamente algoritmos de
\textit{POS Tagging} pré-criados para achar as classes morfológicas e sintáticas
de palavras em tweets que começam com interjeições, como \textit{wow},
\textit{oh}, \textit{wow}, \textit{aha}, \textit{yay}, \textit{yeah},
\textit{nah}, etc. Em seu algoritmo, eles classificam como sarcásticos os textos
que começam por interjeições e possuem um adjetivo ou advérbio imediatamente
após a interjeição, ou então possuem, em algum após a interjeição, ou um
advérbio seguido de adjetivo ou um adjetivo seguido de um substantivo ou um
advérbio seguido de um verbo. Essa abordagem é bastante interessante, pois ela é
bastante simples e, ainda assim, consegue um ótimo resultado de 0.90 $F_1$ no
subconjunto de tweets marcado com a hashtag \textit{sarcasm}.

\subsection{Conjuntos de Características}%
\label{sub:conjuntos-de-caracteristicas}

Antes de prosseguir com as abordagens, essa seção mostra um pouco dos
principais conjuntos de características usadas por essas abordagens. Abordagens
baseadas em regras utilizam determinadas características como principalmente as
classes morfossintáticas das palavras. Entretanto, as abordagens listadas a
seguir fazem uso de conjuntos muito maiores de características retiradas do
texto e vários trabalhos foram realizados para expandir a quantidade de
características possíveis de se utilizar.

Como dito anteriormente, ao criar a matriz de exemplos de entrada $X$, cada
coluna representa uma característica do texto. Dessa forma, o texto fica
agregado em um conjunto de valores numéricos que são acessíveis para a máquina
utilizar e comparar. Ao invés de se comparar dois texto distintos com números de
caracteres e palavras diferentes, utiliza-se um algoritmo para extrair
características (do inglês, ``\textit{features}'') comuns entre os textos e
compará-los por meio dessas características.

Um exemplo é o método chamado \textit{bag-of-words} (em tradução literal
``sacola-de-palavras'') que cria um vetor com, por exemplo, 512 posições de
valores naturais onde cada posição do vetor representa quantas vezes uma
determinada palavra  apareceu no texto. Cada posição do vetor é associada a uma
palavra e, muitas vezes, se utiliza uma outra posição especial para denotar
qualquer palavra que não está no dicionário de palavras selecionadas
previamente. Por exemplo, a primeira posição pode representar quantas vezes a
palavra ``\textit{a}'' aparece no texto, a segunda posição pode representar
quantas vezes a palavra ``\textit{the}'' aparece, e assim por diante. Se a
palavra "Lucas" for lida, então será adicionado um à última posição do vetor,
que é utilizado para contar qualquer palavra que não é uma das outras 511.

(imagem ilustrando BOW)

Esse tipo de abordagem fica entre o baseado em regras e abordagens baseadas em
aprendizado no quesito de explicabilidade dos modelos. Isso porque os
autores, ao invés de criar regras específicas, utilizam métodos de extração de
características, criadas especificamente com o intuito de fazer a detecção de
sarcasmo.

A vantagem dessa abordagem é que geralmente os modelos são mais generalistas do
que os baseados em regras, que são bastante fixas e não se adaptam bem a
diferentes conjuntos de dados. Nesse caso, as mesmas metodologias de extração de
características podem ser aplicadas em um conjunto de dados de textos extraídos
de contextos diferentes (como redes sociais, análises de produtos vendidos
online, aplicativos de troca de mensagens ou falas transcritas).

Entretanto, como desvantagem, o fator manual ainda é muito presente nesse tipo
de abordagem, assim como os métodos baseados em regras. Ao criar um modelo, um
determinado conjunto de características é escolhido \textit{a priori}
arbitrariamente, assim como era o caso das regras no primeiro tipo de abordagem.

\cite{reyes:2012:from-humor} exploram quatro grupos de características dentro de
um contexto mais geral de detecção de humor e ironia. Esses grupos são:
ambiguidade, através dos níveis estrutural, morfossintático e semântico;
polaridade, através de palavras que possuam semântica positiva ou negativa;
imprevisibilidade, através de desbalanceamentos contextuais entre o significado
literal das palavras; e os cenários emocionais, através das emoções passadas por
cada palavras.

\cite{liebrecht:2013:perfect-solution} utilizam uni-, bi- e trigramas como
características do texto. Um n-grama é uma sequência de n palavras do texto.
Portanto, nesse tipo de característica, o unigrama seria o \textit{bag-of-words}
clássico citado acima, com as contagens de cada palavra, já o bigrama se trata
das contagens de duas palavras seguidas. Por exemplo, sempre que as palavras
``\textit{so nice}'' aparecerem em sequência, adiciona-se um à coluna que se
refere a essa sequência.

\cite{reyes:2013:multidimensional-approach} utilizam uma abordagem parecida com
\cite{reyes:2012:from-humor}, com quatro grupos de características: assinaturas,
imprevisibilidade, estilo e cenários emocionais. Cada um dos grupos foca em
várias características. Dentro das assinaturas, por exemplo, há o foco em
pontuações específicas, emojis, citações e palavras em maiúsculas; há o foco em
marcas implícitas que geram oposição entre partes do texto; e há o foco na
compressão temporal, que identifica oposição temporal entre elementos
relacionados.

A grande diferença desse trabalho em relação aos demais está, entretanto, no
grupo de características de estilo. Esse grupo tenta modelar o estilo de escrita
do texto para, assim, fazer a diferenciação entre estilos sarcásticos e não
sarcásticos. Para fazer isso, eles utilizam três tipos de sequências textuais:
n-gramas no nível de caracteres (ao invés de palavras) (abreviado pelos autores
por \textit{c-grams}), \textit{skip-grams} (\textit{s-grams}) e
\textit{skip-grams} de polaridade (\textit{ps-grams}).

Os \textit{c-grams} capturam a frequência de sequências de informação
morfológica como sufixos e prefixos (como \textit{-ly}, \textit{-ing},
\textit{dis-}, \textit{un-}). Os \textit{s-grams} funcionam como n-gramas, mas
com alguns pulos entre palavras e são utilizados para obter relações entre
palavras não adjacentes no texto. Por exemplo, na sentença ``Hoje está chovendo,
quero tanto ir à praia'', um bigrama é representado pela sequência ``Hoje
está'', enquanto um bigrama com pulo de uma palavra seria ``Hoje chovendo''. Por
fim, os \textit{ps-grams} criam uma sequência de rótulos de positividade baseado
nos \textit{s-grams}. Por exemplo, ``Hoje chovendo'' seria rotulado como
``pos-neg'' (positivo e negativo).

\cite{barbieri:2014:modelling-sarcasm}, por sua vez, usam sete grupos de
características léxicas que abstraem o uso de termos específicos e tornam o
processo de detecção de sarcasmo mais genérico e fácil de implementar, não
modelando padrões de palavras como em trabalhos anteriores. Esses grupos são:
frequência, que mede o quão comum é cada palavra utilizada no texto;
escrito-falado (da tradução literal de \textit{written-spoken} utilizado pelos
autores em seu artigo), que funciona como a frequência, mas a frequência que a
palavra é usada em diálogos escritos ou falados; intensidade, que mede o uso de
adjetivos e advérbios para aumentar ou diminuir a intensidade semântica de
outras palavras no texto; estrutura, que mede, por exemplo, o número de
caracteres usados, o número de palavras, o tamanho médio das palavras, o número
de verbos, de substantivos, o número total de pontuações, o número de risadas, o
número de vírgulas, pontos finais, sinais de exclamação, o número de emojis (ou
emoticons), o número de organizações, pessoas, títulos e datas citados pelos
texto; sentimento, que mede valores de positividade entre as palavras e usa
algumas métricas como soma dos valores positivos, soma dos negativos, média da
diferença entre positivos e negativos, entre outros; sinônimos, que calcula
métricas relacionadas aos sinônimos das palavras usadas no texto, como a
quantidade de sinônimos que uma determinada palavra tem e que possuem frequência
de utilização menor do que ela; e ambiguidade, que mede a quantidade de sentidos
possíveis que uma palavra pode ter.

\cite{joshi:2015:context-incongruity} propõem uma nova abordagem baseada em uma
teoria linguística chamada de incongruência de contexto. Eles se baseiam no fato
de que o tempo para um ser humano processar um texto sarcástico depende do grau
de incongruência presente nele e criam características o que chamam de
incongruências explícitas e implícitas. A primeira é caracterizada por palavras
de sentimentos opostos e a segunda é caracterizada por frases de sentimento
implícito, que não se pode detectar através de uma única palavra.

\cite{mishra:2016:harnessing-cognitive} seguem por uma abordagem bastante
diferente das demais, que utiliza características baseadas no movimento
produzido pelos olhos de pessoas lendo textos sarcásticos. Algumas das
características propostas por eles são a fixação da visão em pontos do texto e
saltos mais rápidos entre duas porções do texto do que em relação às demais.
Além disso, eles utilizam um grafo de informação estrutural ao utilizar as
palavras como vértices do grafo e os saltos de visão entre as palavras como
arestas.

\subsection{Abordagens Baseadas em Métodos de Aprendizado}%
\label{sub:abordagens_baseadas_em_metodos_de_aprendizado}



\subsection{Abordagens Baseadas em Contexto}%
\label{sub:abordagens_baseadas_em_contexto}




