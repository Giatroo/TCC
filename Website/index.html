<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width" />

    <title>Trabalho de Conclusão de Curso - Lucas Paiolla Forastiere</title>

    <link rel="shortcut icon" href="./res/favicon.png" type="image/png" />

    <link
      href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;700&display=swap"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="./css/page-landing.css" />
  </head>

  <body>
    <center>
      <div class="header">
        <h1>Bem vindx à página do meu TCC</h1>
        <p class="repo-link">
          <a href="https://github.com/Giatroo/TCC" target="_blank">
            <strong>Repositório do projeto</strong></a
          >
        </p>
        <h2>Detecção de Sarcasmo em Redes Sociais utilizando DeBERTa</h2>
        <p><strong>Aluno:</strong> Lucas Paiolla Forastiere - 11221911</p>
        <p><strong>Supervisor:</strong> Ricardo Marcondes Marcacini</p>
        <p>2022</p>
      </div>

      <div class="proposal">
        <h2>Proposta de Trabalho</h2>

        <p>
          <strong>Introdução do Tema:</strong> Detecção de sarcasmo é um
          importante tópico dentro do processamento de linguagem natural (PLN,
          ou NLP). Esse tema pode ser empregado em vários tipos diferentes de
          sistemas como de mineração de dados, de entendimento da linguagem
          natural ou de diálogo (como chatbots). Entretanto, a detecção de
          sarcasmo é difícil, pois é rara em muitas conversas e, muitas vezes,
          difícil até para nós humanos.
        </p>

        <p></p>

        <p>
          <strong>Objetivos do Trabalho:</strong> No artigo
          <a href="https://arxiv.org/abs/1704.05579" target="_blank"
            >A Large Self-Annotated Corpus for Sarcasm</a
          >, Mikhail Khodak et al. introduzem um conjunto de dados criado para
          treinamento e benchmark de sistemas de detecção de sarcasmo. Nosso
          objetivo é treinar e testar o modelo DeBERTa (Decoding-enhanced Deep
          Bidirectional Transformer with Disentangled Attention) nesse conjunto
          de dados, e comparar resultados com vários outros modelos mais
          clássicos, como o BERT.
        </p>

        <p></p>

        <p>
          <strong>Passos para Atingir os Objetivos:</strong> O cronograma de
          atividades estimadas segue abaixo. Planeja-se inicialmente coletar o
          córpus para realização dos experimentos. Depois disso, vamos fazer um
          modelo base utilizando as bibliotecas
          <a
            href="https://huggingface.co/docs/transformers/index"
            target="_blank"
            ><i>transformers</i></a
          >
          e
          <a href="https://www.sbert.net/" target="_blank"
            ><i>sentence-transformers</i></a
          >. Ao terminar esse baseline, criaremos uma metodologia para
          comparação de modelo (planeja-se comparar com o modelo BERT) e de
          validação dos resultados. Em paralelo com isso, revisarei a literatura
          sobre detecção de sarcamos e uso de transformers para classificação de
          textos. Por fim, para o segundo semestre, o foco será em analisar os
          resultados obtidos utilizando várias métricas (entre elas, métricas
          subjetivas de explicabilidade dos modelos) e também será em finalizar
          a monografia.
        </p>
      </div>

      <div class="paper">
        <h2>Trabalho Final</h2>
        <p>A monografia final está no link abaixo:</p>
        <p class="repo-link">
          <a href="./tese.pdf" target="_blank">
            <strong>Monografia</strong></a
          >
        </p>

      </div>

      <div class="about">
        <h2>Sobre mim</h2>
        <p>
          Eu me chamo Lucas Paiolla Forastiere, sou aluno do Bacharelado em
          Ciência da Computação pelo IME-USP.
        </p>
        <p>
          Minhas áreas de estudo são Machine Learning e Data Science com foco em
          Dados Não-Estruturados (principalmente Texto e Imagens).
        </p>

        <br/>

        <p>lucaspaiolla at usp dot br</p>
        <p>
          <a href="https://github.com/Giatroo" target="_blank">GitHub</a>
        </p>
        <p>
          <a href="https://www.linkedin.com/in/lucas-paiolla/" target="_blank"
            >LinkedIn</a
          >
        </p>
      </div>
    </center>
  </body>
</html>
