<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width" />

    <title>Trabalho de Conclusão de Curso - Lucas Paiolla Forastiere</title>

    <link
      href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;700&display=swap"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="./css/page-landing.css" />
  </head>

  <body>
    <center>
      <div class="header">
        <h1>Bem vindx à página do meu TCC</h1>
        <p class="repo-link">
          <a href="https://github.com/Giatroo/TCC" target="_blank">
            <strong>Repositório do projeto</strong></a
          >
        </p>
      </div>

      <div class="proposal">
        <h2><strong>Proposta de Trabalho</strong></h2>

        <p>
          <strong>Introdução do Tema:</strong> Detecção de sarcasmo é um
          importante tópico dentro do processamento de linguagem natural (PLN,
          ou NLP). Esse tema pode ser empregado em vários tipos diferentes de
          sistemas como de mineração de dados, de entendimento da linguagem
          natural ou de diálogo (como chatbots). Entretanto, a detecção de
          sarcasmo é difícil, pois é rara em muitas conversa e, muitas vezes,
          difícil até para nós humanos.
        </p>

        <p></p>

        <p>
          <strong>Objetivos do Trabalho:</strong> No artigo
          <a href="https://arxiv.org/abs/1704.05579" target="_blank"
            >A Large Self-Annotated Corpus for Sarcasm</a
          >, Mikhail Khodak et al. introduzem um conjunto de dados criado para
          treinamento e benchmark de sistemas de detecção de sarcasmo. Nosso
          objetivo é treinar e testar o modelo DeBERTa (Decoding-enhanced Deep
          Bidirectional Transformer with Disentangled Attention) nesse conjunto
          de dados, e comparar resultados com vários outros modelos mais
          clássicos, como o BERT.
        </p>

        <p></p>


        <p><strong>Passos para Atingir os Objetivos:</strong></p>
      </div>

      <div class="future-schedule">
        <h2><strong>Cronograma previsto para futuras</strong></h2>
        <table class="future-schedule-table">
          <thead>
            <tr>
              <td>Semana</td>
              <td>Tarefas</td>
            </tr>
          </thead>
        </table>
      </div>

      <h2><strong>Cronograma de atividades realizadas até então</strong></h2>
      <table class="schedule-table">
        <thead>
          <tr>
            <td>Data/Semana</td>
            <td>Tarefas</td>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td>30/11/2021</td>
            <td>
              <p>
                Troca de emails com o professor orientador demonstrando
                interesse sobre projeto em NLP ou Visão Computacional;
              </p>
            </td>
          </tr>

          <tr>
            <td>17/01/2022</td>
            <td>
              <p>
                Retomada conversa com o orientador para marcar uma reunião
                inicial;
              </p>
            </td>
          </tr>

          <tr>
            <td>04/02/2022</td>
            <td>
              <p>Conversa inicial com apresentação do tema e abordagens;</p>
            </td>
          </tr>

          <tr>
            <td>07/02/2022</td>
            <td>
              <p>
                Leitura do artigo
                <a href="https://arxiv.org/abs/1704.05579" target="_blank"
                  >A Large Self-Annotated Corpus for Sarcasm</a
                >
                pelo aluno para entender melhor o tema e decidir se aceitaria ou
                proporia outro;
              </p>
            </td>
          </tr>

          <tr>
            <td>18/02/2022</td>
            <td>
              <p>Tema aceito;</p>
              <p>
                Envio de material inicial pelo orientador para o entendimento do
                conjunto de dados;
              </p>
            </td>
          </tr>

          <tr>
            <td>04/03/2022</td>
            <td>
              <p>Reunião inicial com a Professora Nina;</p>
              <p>Troca de email com o orientador sobre próximos passos;</p>
            </td>
          </tr>

          <tr>
            <td>19/03/2022</td>
            <td>
              <p>Criação do repositório GitHub;</p>
              <p>Feita uma primeira introdução do TCC;</p>
            </td>
          </tr>

          <tr>
            <td>31/03/2022</td>
            <td>
              <p>Criação do código inicial;</p>
              <p>Criação de um módulo para baixar e descomprimir o dataset;</p>
              <p>
                Criação de um módulo para selecionar um subconjunto dos dados e
                deixá-los em um formato visualizável;
              </p>
            </td>
          </tr>

          <tr>
            <td>04/04/2022</td>
            <td>
              <p>Adicionada uma lista de materiais para estudar;</p>
              <p>
                Início da leitura do artigo
                <a href="https://arxiv.org/abs/1902.02181" target="_blank"
                  >Attention in Natural Langue Processing</a
                >;
              </p>
              <p>Estudo sobre os modelos Transformers;</p>
              <p>Inicio da criação da home-page;</p>
            </td>
          </tr>

          <tr>
            <td>11/04/2022</td>
            <td>
              <p>
                Correção de erros no código de treinamento inicial do modelo;
              </p>
              <p>Criado esse cronograma =);</p>
            </td>
          </tr>
        </tbody>
      </table>
    </center>
  </body>
</html>
